---
layout: post
title: 金融大数据处理技术笔记
subtitle: FBDP
categories: LectureNotes
tags: FBDP
banner: "/assets/images/banners/toho.jpeg"
---

## CH1 大数据

### 三次信息化浪潮

![image-20230918202007883](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918202007883.png)

### 四种研究范式

![image-20230918202055346](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918202055346.png)

### 大数据

#### 定义

大数据意指一个超大的、难以用现有常规的数据库管理技术和工具 

处理的数据集。

#### 5V特征

* Volume（大体量）：即可从数百TB到数十数百PB，甚至EB的规模

* Variety（多样性）：即大数据包括各种格式和形态的数据
* Velocity（时效性）：即很多大数据需要在一定的时间限度下得到及时处理
* Veracity（准确性）：即处理的结果要保证一定的准确性
* Value（大价值）：即大数据包含很多深度的价值，大数据分析挖掘和利用将带来巨大的商业价值

#### 结构化/半结构化/非结构化

* 结构化数据：结构化数据是指在预定义的数据模型中组织的数据，通常存储在关系数据库中。它们有严格的格式和规则，例如行和列的表格。
* 半结构化数据：半结构化数据介于结构化数据和非结构化数据之间。它们没有严格的数据模型，但有某种形式的结构。例如JSON就是一个常见的数据格式，它有一些形式的规范（例如分隔），但可以存储数值，字符串等多种类型的元素。
* 非结构化数据：非结构化数据是没有特定结构的数据。这种数据类型包括文本、视频、音频、社交媒体发布等。

#### 不同类型

![image-20230918202424665](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918202424665.png)

#### 大数据问题的特点和研究原则

##### 基本特点

* 大数据来自应用行业，**具有极强的行业应用需求特性**
* **数据规模极大**，达到PB甚至EB量级，超过任何传统数据库系统的处理能力
* 大数据处理给传统计算技术带来极大挑战，大多数传统算法在面向大数据处理时都面临问题，需要重写

##### 基本原则

* 应用需求为导向：以行业应用问题和需求为出发点
* 领域交叉为桥梁：行业、IT产业、学术界协同
* 计算技术为支撑：研究解决涉及的计算技术问题

#### 大数据的引擎

是软件，软件改变世界！

#### 大数据研究基本目标

以有效的信息技术手段和计算方法，获取、处理和分析各类应用行

业的大数据，发现和提取数据的内在价值，为行业提供高附加值的

应用和服务。

* 技术手段：信息技术和计算方法

* 核心目标：价值发现
* 效益目标：形成高附加值行业应用

#### 大数据研究的挑战和基本途径

##### 挑战

* 数据规模导致难以应付的存储量
* 数据规模导致传统算法失效
* 大数据复杂的数据关联性导致高复杂度的计算

##### 基本途径

* 寻找新算法降低计算复杂度
* 降低大数据尺度，寻找数据尺度无关算法
* 大数据并行化处理

#### 大数据典型和热点技术问题

![image-20230918203024459](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918203024459.png)

#### 大数据涉及的关键技术

![image-20230918203040453](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918203040453.png)

### 金融大数据

金融数据：一般具有“流数据”特征，需要在短时间内快速处理。

具有逻辑关系紧密，处理实时性要求高，可展示性需求强等特征。

* 数据分析技术：数据挖掘，机器学习等AI技术
* 数据管理技术：关系型和非关系型数据管理、数据融合和集成技术、ETL等技术
* 数据处理技术：分布式计算，内存计算，流处理技术等
* 数据展示技术：可视化技术、历史流展示技术、空间信息流展示技术等。

## CH2 并行计算技术

### 如何提高计算机性能？

为什么要并行计算技术？为了提高计算机性能！

* 提高处理器字长
* 提高集成度（限制：摩尔定律）
* 流水线等微体系结构技术
* 提高处理器频率

但是存在以下问题，导致单核处理器性能提升接近极限：

* VLSI集成度不可能无限制提高
* 处理器的指令级并行度提升接近极限（ILP墙）
* 处理器速度和存储器速度差异越来越大（CPU约为1ns，而主存约为100ns）
* 功耗和散热大幅增加超过芯片承受能力

### 并行计算技术的发展趋势和影响

* 越来越多的研究和应用领域需要使用并行计算技术

	* 并行计算技术将渗透到每个计算应用领域，尤其是涉及到大规模数据和复杂计算的应用领域

* 并行计算技术将对传统计算技术产生革命性的影响

	* 并行计算技术将影响传统计算技术的各个层面，与传统计算技术相互结合产生很多新的研究热点和课题
	* 很多传统的串行算法和计算方法都将需要重新研究和设计其并行化算法和计算方法

### 并行计算技术的分类

![image-20230918204013792](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204013792.png)

#### 弗林分类

![image-20230918204102025](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204102025.png)

![image-20230918204042637](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204042637.png)

#### 并行类型分类

![image-20230918204123431](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204123431.png)

#### 存储访问结构分类

![image-20230918204135426](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204135426.png)

#### 系统类型分类

![image-20230918204146473](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204146473.png)

![image-20230918204245145](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204245145.png)

![image-20230918204254576](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204254576.png)

#### 计算特征分类

![image-20230918204304001](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204304001.png)

#### 并行程序设计模型/方法分类

![image-20230918204320137](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204320137.png)

#### 发展趋势

![image-20230918204816521](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918204816521.png)

### 并行计算主要技术问题

#### 多核/多处理器网络互联结构技术

![image-20230918210121018](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918210121018.png)

#### 存储访问体系结构

![image-20230918213547843](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213547843.png)

#### 分布式数据与文件管理

![image-20230918213558993](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213558993.png)

#### 并行计算任务的分解与算法设计

![image-20230918213607258](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213607258.png)

#### 并行程序设计模型和方法

![image-20230918213619916](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213619916.png)

![image-20230918213624978](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213624978.png)

#### 数据同步访问和通信控制

![image-20230918213634694](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213634694.png)

#### 可靠性设计与容错技术

![image-20230918213641126](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213641126.png)

#### 并行计算软件框架平台

![image-20230918213653843](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213653843.png)

#### 系统性能评估和程序并行度评估

![image-20230918213702207](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213702207.png)

![image-20230918213711778](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918213711778.png)

### MPI并行程序设计

#### MPI是什么？

MPI (Message Passing Interface)，基于消息传递的高性能并行计算编程接口。MPI在处理器间以消息传递方式进行数据通信和同步，以库函数形式为程序员提供了一组易于使用的编程接口。

特点：提供可靠的、面向消息的通信；在高性能科学计算领域广泛使用，适合于处理计算密集型的科学计算；独立于语言的编程规范，可移植性好。

#### MPI并行程序设计的时候需要注意什么？

* 消息传递并行程序设计

	* 用户必须通过显式地发送和接收消息来实现处理机间的数据交换。

	* 每个并行进程均有自己独立的地址空间，相互之间访问不能直接进行，必须通过显式的消息传递来实现。

* 并行计算粒度大，特别适合于大规模可扩展并行算法

	* 要求用户很好地分解问题，组织不同进程间的数据交换，并行计算粒度大。

#### MPI主要功能（通信方式）

* 用常规语言编程方式，所有节点运行同一个程序，但处理不同的数据

	* 提供点对点通信(Point-point communication)

	* 提供同步通信功能（阻塞通信）

	* 提供异步通信功能（非阻塞通信）

* 提供节点集合通信(Collective communication)

	* 提供一对多的广播通信

	* 提供多节点计算同步控制

	* 提供对结果的规约(Reduce)计算功能

* 提供用户自定义的复合数据类型传输

方式及相关接口整理如下：

MPI提供三大类通信方式：

* 点对点通信
  * 同步通信：阻塞式通信，等待通信操作完成后才返回。
    * *MPI_Send (buf, count, datatype, dest, tag, comm)* : 发送一个消息
    * *MPI_Recv (buf, count, datatype, source, tag, comm, status)* : 接受消息
  * 异步通信：非阻塞式通信，不等待通信操作完成即返回。
    *  *MPI_ISend (buf, count, datatype, dest, tag, comm, request)* : 异步发送
    * *MPI_IRecv (buf, count, datatype, source, tag, comm, status, request)* 异步接受消息
    * *MPI_Wait (request, status)* : 等待非阻塞数据传输完成
    * *MPI_Test (request, flag, status)* : 检查是否异步数据传输确实完成
* 节点集合通信
  * 一对多的广播通信。主要有以下接口：
    * *MPI_BCAST*: 一对多的广播式发送
  * 多节点计算同步控制。主要有以下接口：
    * *MPI_GATHER*：多个进程的消息以某种次序收集到一个进程
    * *MPI_SCATTER*：将一个信息划分为等长的段依次发送给其它进程
  * 对结果的规约（Reduce）计算功能
    * *MPI_Reduce*：将一组进程的数据按照指定的操作方式规约到一起并传送给一个进程
* 用户自定义的复合数据类型传输

#### MPI程序

##### MPI基本程序结构

![image-20230918215212360](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215212360.png)

##### MPI并行程序设计接口

![image-20230918215255309](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215255309.png)

![image-20230918215301625](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215301625.png)

![image-20230918215443383](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215443383.png)

![image-20230918215447655](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215447655.png)

##### MPI编程示例

![image-20230918215456069](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215456069.png)

![image-20230918215508951](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215508951.png)

![image-20230918215516128](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215516128.png)

![image-20230918215520244](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215520244.png)

![image-20230918215523816](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215523816.png)

![image-20230918215527512](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215527512.png)

![image-20230918215531278](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215531278.png)

#### 节点集合通信接口

提供一个进程与多个进程间同时通信的功能。

![image-20230918215554628](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215554628.png)

##### 集合通信功能

* ![image-20230918215838357](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215838357.png)

##### 数据规约操作

![image-20230918215831126](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918215831126.png)

![image-20230918220017793](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918220017793.png)

![image-20230918220021991](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918220021991.png)

![image-20230918220027955](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230918220027955.png)

#### MPI特点和不足

* **MPI的特点**
	* 灵活性好，适合于各种计算密集型的并行计算任务
	* 独立于语言的编程规范，可移植性好
	* 有很多开放机构或厂商实现并支持
* **MPI的不足**
	* 无良好的数据和任务划分支持
	* 缺少分布文件系统支持分布数据存储管理
	* 通信开销大，当计算问题复杂、节点数量很大时，难以处理，性能大幅下降
	* 无节点失效恢复机制，一旦有节点失效，可能导致计算过程无效
	* 缺少良好的构架支撑，程序员需要考虑以上所有细节问题，程序设计较为复杂

## CH3 MapReduce简介

### MapReduce的基本模型和处理思想

#### 三大设计思想

* **分而治之：处理大数据**

  对相互间不具有计算依赖关系的大数据，实现并行最自然的办法就是采取**分而治之**的策略。

* **并行抽象模型：Mapper与Reducer**

  MPI等并行计算方法缺少高层并行编程模型，为了克服这一缺陷，MapReduce借鉴了Lisp函数式语言中的思想，用Map和Reduce两个函数提供了高层的并行编程抽象模型。

* **统一构架，隐藏系统层细节**

  MPI等并行计算方法缺少统一的计算框架支持，程序员需要考虑数据存储、划分、分发、结果收集、错误恢复等诸多细节；为此，MapReduce设计并提供了统一的计算框架，为程序员隐藏了绝大多数系统层面的处理细节。

#### 分而治之：处理大数据

对相互间不具有计算依赖关系的大数据，实现并行最自然的办法就是采取**分而治之**的策略。

**不可分拆的计算任务或相互间有依赖关系的数据无法进行并行计算！**

并行化计算示例：

![image-20230925150338530](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925150338530.png)

![image-20230925150344063](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925150344063.png)

![image-20230925150400486](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925150400486.png)

概念：

* Master：负责划分和分配任务
* Worker：负责数据块计算

#### 构建抽象模型：Mapper与Reducer

##### Map和Reduce的工作方式

MapReduce借鉴了**函数式设计语言Lisp**的设计思想。

* Lisp定义了可对列表元素进行整体处理的各种操作，如：
  * (add #(1 2 3 4) #(4 3 2 1)) 将产生结果： #(5 5 5 5)

* Lisp中也提供了类似于Map和Reduce的操作

  * 如: (**map** ’vector #+#(1 2 3 4 5) #(10 11 12 13 14)) 

  * 通过定义加法map运算将2个向量相加产生结果#(11 13 15 17 19)

    (**reduce** #’+#(11 13 15 17 19)) 通过加法归并产生累加结果75

![image-20230925151537434](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925151537434.png)

**Map: 对一组数据元素进行某种重复式的处理**

**Reduce: 对Map的中间结果进行某种进一步的结果整理**

![image-20230925151556758](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925151556758.png)

示例：

![image-20230925151149013](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925151149013.png)

##### Map和Reduce操作的抽象描述

![image-20230925151926611](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925151926611.png)

##### 基于Map和Reduce的并行计算模型

![image-20230925152049032](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925152049032.png)

* 各个map函数对所划分的数据并行处理，从不同的输入数据产生不同的中间结果输出。

* 各个reduce也各自并行计算，各自负责处理不同的中间结果数据集合。

* 进行reduce处理之前，必须等到所有的map函数做完，因此，在进入reduce前需要有一个同步障(barrier)；这个阶段也负责对map的中间结果数据进行收集整理(aggregation & shuffle)处理，以便reduce更有效地计算最终结果。

* 最终汇总所有reduce的输出结果即可获得最终结果。

##### 如何提供统一的计算框架

MapReduce提供一个统一的计算框架，可完成：

* 计算任务的划分和调度

* 数据的分布存储和划分

* 处理数据与计算任务的同步

* 结果数据的收集整理(sorting, combining, partitioning…)

* 系统通信、负载平衡、计算性能优化处理

* 处理系统节点出错检测和失效恢复

##### MapReduce最大的亮点

**通过抽象模型和计算框架把需要做什么(what need to do)与具体怎么做(how to do)分开了**，为程序员提供一个抽象和高层的编程接口和框架。

程序员仅需要关心其应用层的具体计算问题，**仅需编写少量的处理应用本身计算问题的程序代码。**

如何具体完成这个并行计算任务所相关的诸多**系统层细节被隐藏起来，交给计算框架去处理**：从分布代码的执行，到大到数千小到单个节点集群的自动调度使用。

##### *MapReduce提供的主要功能

MapReduce有四大主要功能：

* **数据划分和计算任务调度**

  提交的一个计算作业（Job)将被划分为很多个计算任务（Tasks)。

  任务调度功能主要负责为这些划分后的计算任务分配和调度计算结点（Map 结点或 Reduce 结点），同时负责监控这些结点的执行状态，以及 Map 结点执行的同步控制，也负责进行一些计算性能优化处理。例如，对最慢的计算任务采用多备份执行，选最快完成者作为结果。

* **数据/程序互定位**

  为了减少数据通信量，一个基本原则是本地化数据处理，即一个计算结点尽可能处理其本地磁盘上分布存储的数据，这实现了代码向数据的迁移。

  当无法进行这种本地化数据处理时，再寻找其他可用结点并将数据从网络上传送给该结点（数据向代码迁移)，但将尽可能从数据所在的本地机架上寻找可用结点以减少通信延迟。

* **出错处理**

  在以低端商用服务器构成的大规模 MapReduce 计算集群中，结点硬件（主机、兹盘、内存等）出错和软件有缺陷是常态。因此，MapReduce 架构需要能检测并隔离出错结点，并调度分配新的结点接管出错结点的计算任务。

* **分布式数据存储与文件管理**

  海量数据处理需要一个良好的分布数据存储和文件管理系统作为支撑，该系统能够把海量数据分布存储在各个结点的本地磁盘上，但保持整个数据在逻辑上成为一个完整的数据文件。

  为了提供数据存储容错机制，该系统还要提供数据块的多备份存储管理能力。

* **Combiner 和 Partitioner**

  为了减少数据通信开销，中间结果数据进入 Reduce 结点前需要进行合并（Combine）处理，即把具有同样主键的数据合并到一起避免重复传送。

  一个 Reduce 结点所处理的数据可能会来自多个 Map 结点，因此，Map 结点输出的中间结果需使用一定的策略进行适当的划分（Partition）处理，保证相关数据发送到同一个Reduce结点上。

#### 自动并行化并隐藏系统层细节

![image-20230925152844126](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925152844126.png)

![image-20230925152848119](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925152848119.png)

### MapReduce的主要思想和特征

#### 向“外”横向扩展，而非向“上”纵向扩展

![image-20230925153231150](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153231150.png)

#### 失效被认为是常态

![image-20230925153237534](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153237534.png)

#### 把处理向数据迁移

![image-20230925153244540](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153244540.png)

#### 顺序处理数据、避免随机访问数据

![image-20230925153251146](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153251146.png)

#### 为应用开发者隐藏系统层细节

![image-20230925153328951](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153328951.png)

#### 平滑无缝的可扩展性

![image-20230925153337104](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153337104.png)

## CH4 Google MapReduce基本架构

回顾一下Google的三驾马车：GFS、MapReduce、Bigtable

![image-20230925153542156](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153542156.png)

### Google MapReduce的基本工作原理

#### Google MapReduce并行处理的基本过程

![image-20230925153919653](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153919653.png)

![image-20230925153926333](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153926333.png)

![image-20230925153933224](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153933224.png)

![image-20230925153937897](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153937897.png)

![image-20230925153942367](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925153942367.png)

#### 失效处理

* 主节点失效

  * 主节点中会周期性地设置检查点(checkpoint)，检查整个计算作业的执行情况，一旦某个任务失效，可以从最近有效的检查点开始重新执行，避免从头开始计算的时间浪费。

  * 如果只有一个Master，它不太可能失败；因此，如果Master失败，将中止MapReduce计算。


* 工作节点失效
  * 工作节点失效是很普遍发生的，主节点会周期性地给工作节点发送检测命令，如果工作节点没有回应，这认为该工作节点失效，主节点将终止该工作节点的任务并把失效的任务重新调度到其它工作节点上重新执行。


#### 带宽优化

* 问题

	* 大量的键值对数据在传送给Reduce节点时会引起较大的通信带宽开销。

* 解决方案

	* 每个Map节点处理完成的中间键值对将由combiner做一个合并压缩，即把那些键名相同的键值对归并为一个键名下的一组数值。

![image-20230925154222696](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925154222696.png)

#### 计算优化

* **问题**
	* Reduce节点必须要等到所有Map节点计算结束才能开始执行，因此，如果有一个计算量大、或者由于某个问题导致很慢结束的Map节点，则会成为严重的“拖后腿者”。
	
* **解决方案**
* 把一个Map计算任务让多个Map节点同时做，取最快完成者的计算结果。

#### 用数据分区解决数据相关性问题

* **问题**
  * 一个Reduce节点上的计算数据可能会来自多个Map节点，因此，为了在进入Reduce节点计算之前，需要把属于一个Reduce节点的数据归并到一起。


* **解决方案**

  * 在Map阶段进行了Combining以后，可以根据一定的策略对Map输出的中间结果进行分区(partitioning)，这样即可解决以上数据相关性问题避免Reduce计算过程中的数据通信。

  例如：有一个巨大的数组，其最终结果需要排序，每个Map节点数据处理好后，为了避免在每个Reduce节点本地排序完成后还需要进行全局排序，我们可以使用一个分区策略如:(d%R)，d为数据大小，R为Reduce节点的个数，则可根据数据的大小将其划分到指定数据范围的Reduce节点上，每个Reduce将本地数据排好序后即为最终结果。


### 分布式文件系统GFS的工作原理

#### GPS是什么？

Google GFS是一个基于分布式集群的大型分布式文件系统，为MapReduce计算框架提供数据存储和数据可靠性支撑；

GFS是一个构建在分布节点本地文件系统之上的一个逻辑上文件系统，它将数据存储在物理上分布的每个节点上，但通过GFS将整个数据形成一个逻辑上整体的文件。

#### Google GFS的基本设计原则

* **廉价本地磁盘分布存储**
  * 各节点本地分布式存储数据，优点是不需要采用价格较贵的集中式磁盘阵列，容量可随节点数增加自动增加

* **多数据自动备份解决可靠性**
  * 采用廉价的普通磁盘，把磁盘数据出错视为常态，用自动多数据备份存储解决数据存储可靠性问题


* **为上层的MapReduce计算框架提供支撑**
  * GFS作为向上层MapReduce执行框架的底层数据存储支撑，负责处理所有的数据自动存储和容错处理，因而上层框架不需要考虑底层的数据存储和数据容错问题


#### Google GFS的基本架构和工作原理

##### 基本架构

![image-20230925155258227](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925155258227.png)

###### GFS Master

![image-20230925155343542](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925155343542.png)

###### GFS ChunkServer

![image-20230925155418509](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925155418509.png)

##### 工作原理：数据访问工作过程

1. 在程序运行前，数据已经存储在GFS文件系统中；程序运行时应用程序会告诉GFS Server所要访问的文件名或者数据块索引是什么。

   ![image-20230925143810439](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925143810439.png)

2. GFS Server根据文件名和数据块索引在其文件目录空间中查找和定位该文件或数据块，找出数据块具体在哪些ChunkServer上；将这些位置信息回送给应用程序。

   ![image-20230925143831698](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925143831698.png)

3. 应用程序根据GFS Server返回的具体Chunk数据块位置信息，直接访问相应的ChunkServer。

   ![image-20230925143855037](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925143855037.png)

4. 应用程序根据GFS Server返回的具体Chunk数据块位置信息直接读取指定位置的数据进行计算处理。

   ![image-20230925143908898](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925143908898.png)

以上过程的特点是：应用程序访问具体数据的时候不需要经过GFS Master，避免了Master成为访问性能瓶颈；另一方面，由于大量数据会存储在不同的ChunkServer中，应用可实现并发访问。

##### GFS的系统管理技术

* **大规模集群安装技术**：如何在一个成千上万个节点的集群上迅速部署GFS，升级管理和维护等。

* 故障检测技术：GFS是构建在不可靠的廉价计算机之上的文件系统，节点数多，故障频繁，如何快速检测、定位、恢复或隔离故障节点。

* **节点动态加入技术**：当新的节点加入时，需要能自动安装和部署GFS。

* **节能技术**：服务器的耗电成本大于购买成本，Google为每个节点服务器配置了蓄电池替代UPS，大大节省了能耗。

### 分布式结构化数据表BigTable的基本工作原理

#### BigTable的基本作用和设计思想

![image-20230925160241919](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160241919.png)

GPS是一个分布式文件管理系统，不适合用来存储和管理结构化数据。因此在GFS之上又设计了一个结构化数据存储和访问管理系统—BigTable，为应用程序提供比单纯的文件系统更方便、更高层的数据操作能力，同时提供了一定粒度的结构化数据操作能力。

**但是它结构化粒度低，没有事务处理能力，因此不是真正意义上的数据库。**

#### BigTable的设计动机和目标

* 广泛的适用性：为一系列服务和应用而设计的数据存储系统，可满足对不同类型数据的存储和操作需求

* 很强的可扩展性：根据需要可随时自动加入或撤销服务器节点

* 高吞吐量数据访问：提供P级数据存储能力，每秒数百万次的访问请求

* 高可用性和容错性：保证系统在各种情况下都能正常运转，服务不中断

* 自动管理能力：自动加入和撤销服务器，自动负载平衡

* 简单性：系统设计尽量简单以减少复杂性和出错率

#### BigTable数据模型

BigTable主要是一个分布式多维表，表中的数据通过：

* 一个行关键字（row key）

* 一个列关键字（column key）

* 一个时间戳（timestamp）

进行索引和查询定位的。

BigTable对存储在表中的数据不做任何解释，一律视为字节串，具体数据结构的实现由用户自行定义。

BigTable查询模型

* (row:string, column:string,time:int64)->结果数据字节串

* 支持查询、插入和删除操作

![image-20230925145049058](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925145049058.png)

BigTable数据存储格式：

* 行(Row):大小不超过64KB的任意字符串。表中的数据都是根据行关键字进行排序的。

  com.cnn.www就是一个行关键字，指明一行存储数据。URL地址倒排好处是：1)同一地址的网页将被存储在表中连续的位置，便于查找；2)倒排便于数据压缩，可大幅提高数据压缩率。

* 子表(Tablet)：一个大表可能太大，不利于存储管理，将在水平方向上被分为多个子表。

  ![image-20230925145235130](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925145235130.png)

* 列(Column): BigTable将列关键字组织成为“列族”(column family)，每个族中的数据属于同一类别，如anchor是一个列族，其下可有不同的表示一个个超链的列关键字。一个列族下的数据会被压缩在一起存放（按列存放）。因此，一个列关键字可表示为： 族名：列名(family:qualifier)

  content、anchor都是族名；而cnnsi.com和my.look.ca则是anchor族中的列名。

  ![image-20230925145449795](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925145449795.png)

* 时间戳(time stamp):很多时候同一个URL的网页会不断更新，而Google需要保存不同时间的网页数据，因此需要使用时间戳来加以区分。

  为了简化不同版本的数据管理，BigTable提供给了两种设置：

  * 保留最近的n个版本数据
  * 保留限定时间内的所有不同版本数据

  ![image-20230925145607139](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925145607139.png)

#### BigTable基本架构

![image-20230925160602703](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160602703.png)

![image-20230925160613301](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160613301.png)

![image-20230925160617337](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160617337.png)

![image-20230925160621832](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160621832.png)

![image-20230925160703085](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160703085.png)

![image-20230925160707450](https://repo-for-md.oss-cn-beijing.aliyuncs.com/img/image-20230925160707450.png)
